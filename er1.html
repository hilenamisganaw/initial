<html>
<head>
  <link href="https://fonts.googleapis.com/css?family=Handlee" rel="stylesheet">
<style>

  #container, h1 {
    width: 50%;
    margin: 0 auto;
    background-color: #FFD3B5;
    color: #FF8C94;
    border: 2px solid white;
    border-radius: 5px;
    margin-top: 20px;
    padding: 10px 20px;
}
  body {
    font-size: 18px;
    font-family: 'Handlee', cursive;
      background-color: #FF8C94;
}
<div>
  h1 {
    text-align: center;
    font-size: 18px;
    font-family: 'Handlee', cursive;
}
</style>
<body>
  <h1>
    Ethical Reflection One: Machine Bias
  </h1>
  <div id="container">
  <p>
    Machine Bias is a very prevalent issue within technology that, like most systems in America, caters only to white faces- literally.
    Essentially, it does exactly what we hear too often from racists in denial:
    “I don’t see color.”
  </p>
  <p>
    Okay.
  </p>
  <p>
    Technology, specifically facial recognition, is a very targeted application. It’s made to recognize race and make determinations from there.
    In ProPublica’s findings of the machine bias in Northpointe’s technology, they discovered that of the criminals charged with misdemeanors,
    black people were labeled as “more risky” than white people. However, more white people were charged again as reoffenders than people of
    color. One can see how controversial this technology could be perceived.
</p>
<p>
  Machine bias is a toxic system that only enforces the disenfranchisement of black people in America. The fact that it is an accepted practice
  in our already tainted criminal justice system is quite upsetting. Algorithms made by the very same people who impose mass incarceration
  shouldn’t be administered because they are inevitably doing the very same thing.
</p>
<p>
  But that’s none of my business.
</p>
<p>
  *sips tea emphatically*
</p>
</div>

</body>
